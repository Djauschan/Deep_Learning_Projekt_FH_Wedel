use_gpu: true
model_parameters:
  transformer:
    num_heads: 1
    num_layers: 1
    d_ff: 200
    seq_len_encoder: 50
    seq_len_decoder: 10
    dropout: 0.1
training_parameters:
  batch_size: 150
  epochs: 10000
  learning_rate: 0.0001
  loss: "rmse" # Options: "mse", "rmse", "rmsle"
  optimizer: "sgd" # Options: "adam", "sgd"
  momentum: 0.2
dataset_parameters:
  read_all_files: false
  data_usage_ratio: 0.115 # Only the last 50% of the read data are used in the dataset
  subseries_amount: 1 # The time series will be cut into 10 subseries (which each consist of a train and validation set)
  validation_split: 0.1 # The last 10% of timestamps in a subseries are used for validation
  create_new_file: true # This parameter must be set to true if the symbols to be read in are changed.
  scaler: "MinMaxScaler" # Options: "StandardScaler", "MinMaxScaler", "QuantileTransformer", "PowerTransformer"
  data_file: "data/output/Multi_Symbol.csv"
  encoder_symbols:
  # stocks
    - "art1"
    - "art2"
    - "AAPL"
    - "AAL"
    - "AMD"
#    - "C"
    - "MRNA"
    - "NIO"
    - "NVDA"
#    # - "SNAP"
#    # - "SQ"
    - "TSLA"
  # ETFs
#    - "ACWI"
  # indices
#    - "DXY"
    # - "SPX"
    # - "DJCIGC"
    # - "DJCISI"
    # - "DJCIEN"
    # - "DJCIIK"
    # - "DJI"
    # - "DJINET"
#    - "COMP"
    # - "W5000"
  decoder_symbols:
#    - "art1"
#    - "art2"
#    - "art2"
#    - "AMD"
    - "AAPL"
#    - "AAL"
#    - "MRNA"
#    - "NIO"
#    - "NVDA"
#    - "TSLA"