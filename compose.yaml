# To only start a specific services, run: docker compose up <service_name> 
# (e.g. docker compose up train_transformer)

# Define services for the Docker Compose configuration
services:

  base_service:
    # Specify the NVIDIA runtime for GPU support
    runtime: nvidia
    environment:
      # Specify which GPUs to use
      - NVIDIA_VISIBLE_DEVICES=all
      # Specify the default configuration file
      - CONFIG_PATH=data/test_configs/training_config_tt.yaml

    # Specify the build context for this service (current directory)
    build:
      context: .

    # Bind mount the current directory to /app in the container
    volumes:
      - .:/app

  # Service to train a transformer model
  train_transformer:

    # This service extends the base_service
    extends:
      service: base_service

    # Map port 5001 on the host to port 5000 in the container
    ports:
      - 5001:5000

    # Specify the command to run when the container starts
    # This command starts the training process
    command:
      [
        "python",
        "-m",
        "src_transformers.main",
        "-c",
        "${CONFIG_PATH}",
        "-p",
        "train"
      ]

  # Service to use a trained transformer model to predict
  predict_transformer:

    # This service extends the base_service
    extends:
      service: base_service

    # Map port 5002 on the host to port 5000 in the container
    ports:
      - 5002:5000

    # Specify the command to run when the container starts
    # This command starts the prediction process
    command:
      [
        "python",
        "-m",
        "src_transformers.main",
        "-c",
        "${CONFIG_PATH}",
        "-p",
        "predict"
      ]

  # Service to visualize data
  visualize_data:

    # This service extends the base_service
    extends:
      service: base_service

    # Map port 5003 on the host to port 5000 in the container
    ports:
      - 5003:5000

    # Specify the command to run when the container starts
    # This command starts the visualization process
    command:
      [
        "python",
        "-m",
        "src_transformers.utils.visualize_data",
        "${CONFIG_PATH}"
      ]

  # Service to start auto-sklearn
  auto_sklearn:

    # This service extends the base_service
    extends:
      service: base_service

    # Map port 5004 on the host to port 5000 in the container
    ports:
      - 5004:5000

    # Specify the command to run when the container starts
    # This command starts the auto-sklearn process
    command:
      [
        "python",
        "-m",
        "src_transformers.models.auto_sklearn",
        "${CONFIG_PATH}"
      ]

  # Service to monitor training with tensorboard
  tensorboard:

    # Use the latest tensorflow image
    image: tensorflow/tensorflow:latest

    # Map port 6006 on the host to port 6006 in the container (default TensorBoard port)
    ports:
      - 6006:6006

    volumes:
      - ./runs:/runs/ # Mount the 'runs' directory in the current directory to '/runs' in the container
    command: [ "tensorboard", "--logdir=./runs/", "--bind_all" ]
